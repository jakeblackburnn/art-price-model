{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87f65d2-4545-4c69-9e44-4853782606ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2a9dd4-0581-4f1f-b19b-77c091cdee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "import pandas\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ccb8802-406f-4440-b99d-76fd9c5e660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "MPS built: True\n",
      "MPS available: True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "COLOR_CHANNELS = 3\n",
    "EPOCHS = 12\n",
    "LEARNING_RATES = [0.0001, 0.001, 0.01, 0.1]\n",
    "ACCURACY_THRESHOLD = 0.2\n",
    "\n",
    "# GPU acceleration\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebccefa-b3fc-40c5-8737-b79131770442",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pretrained Model - resnet101\n",
    "reference:\n",
    "\n",
    "https://arxiv.org/abs/1512.03385\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "992065e1-fc42-4be5-8caf-15e19b7f7824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "                                                                                         \n",
    "resnet101 = models.resnet101(weights=True)          # load resnet model \n",
    "\n",
    "resnet_layers = resnet101.children()                # split resnet into array of layers \n",
    "resnet_layers = list(resnet_layers)[:-1]            # remove final layer from the array\n",
    "\n",
    "    \n",
    "resnet101 = torch.nn.Sequential(*resnet_layers).to(device)     # recombine modified layers, move to gpu if available\n",
    "   \n",
    "resnet101.eval()                                     # Set model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559423a0-0e4d-4e37-9efe-6f3a99d3ce35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Custom Dataset Class - ArtworkDataset\n",
    "\n",
    "reference:\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3475f559-1086-471e-96a0-0fd9a3f825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5278c76-2aee-4e19-8d3f-5577cf10f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ArtworkDataset(Dataset):\n",
    "\n",
    "    \n",
    "    def __init__(self, artworks_frame, artwork_images_path, transform=None):\n",
    "        \n",
    "            # remove USD and whitespace from end of price strings \n",
    "            # convert price strings to floats\n",
    "        artworks_frame['price'] = artworks_frame['price'].str.replace('USD', '', regex=False).str.strip().astype(float)\n",
    "\n",
    "        artworks_frame = artworks_frame[['price']] # trim dataframe to only hold price column\n",
    "\n",
    "        #print(type(artworks_frame))\n",
    "        #print(artworks_frame)\n",
    "        \n",
    "\n",
    "        scaled_prices = scaler.fit_transform(artworks_frame) # array of [0, 1] normalized prices\n",
    "\n",
    "        #print(type(artworks_frame))\n",
    "        #artworks_frame = pd.DataFrame(artworks_frame, columns=['price']) # convert back to dataframe\n",
    "\n",
    "        artworks_frame['price'] = scaled_prices # set prices to scaled prices within dataframe\n",
    "\n",
    "  \n",
    "\n",
    "        \n",
    "\n",
    "            # add dataframe, image path, and transform to dataset\n",
    "\n",
    "        self.artworks_frame      = artworks_frame\n",
    "        self.artwork_images_path = artwork_images_path\n",
    "        self.transform           = transform\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.artworks_frame)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):     \n",
    "                                                                # Get image path\n",
    "        image_path = self.artwork_images_path + \"/\" + \"image_\" + str(idx + 1) + \".png\" # assume index + 1 is same as image id\n",
    "\n",
    "          \n",
    "        image = read_image(image_path, mode=ImageReadMode.RGB).float() # Get image as tensor with only RGB channels\n",
    "        price = self.artworks_frame.iloc[idx]['price']                 # Get price\n",
    "\n",
    "        if self.transform:                                     # Apply transformation to image\n",
    "            image  = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(price, dtype=torch.float32) # Return transformed image and Price tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb2428-1968-49e0-bba5-5acdf21f46bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Download - art-price-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a7336d-2a87-420c-8232-bc95dd4b3683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.7)\n",
      "DATASET DOWNLOADED.   path:   /Users/jackblackburn/.cache/kagglehub/datasets/flkuhm/art-price-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "    import kagglehub\n",
    "    \n",
    "    print( \"DATASET DOWNLOADED.   path:   \" + kagglehub.dataset_download(\"flkuhm/art-price-dataset\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8730cd9-e28f-483b-92a3-7a22263ea4b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preprocessing - get_art_price_dataset(), get_image_transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66cd160c-6d70-46a4-95f8-ecfd1d6deb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_price_dataset_path():\n",
    "    \n",
    "                            # ensure dataset is downloaded & get path\n",
    "    import kagglehub\n",
    "    \n",
    "    dataset_path = kagglehub.dataset_download(\"flkuhm/art-price-dataset\")\n",
    "    \n",
    "    \n",
    "    print( \"DATASET FOUND.   path:   \" + kagglehub.dataset_download(\"flkuhm/art-price-dataset\") )\n",
    "    \n",
    "                                            # get csv file and image directory paths\n",
    "    \n",
    "    csv_path      = dataset_path + \"/\" + \"artDataset.csv\" # csv file of data about artworks\n",
    "    artworks_path = dataset_path + \"/\" + \"artDataset\"     # directory of artwork images\n",
    "\n",
    "    return csv_path, artworks_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c471fa9-67b7-419a-a23a-f435f566dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_transform():\n",
    "\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    # Define a data transformation for image preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image data\n",
    "    ])\n",
    "\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fcb8d-9a2f-4ca4-a77c-1ad8e5a46e35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-Layer Perceptron Class - Net, train(), validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "750d3159-441a-4223-9daf-5d606419c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Net(torch.nn.Module):                     # Define Multi-Layer Perceptron Class\n",
    "    \n",
    "    def __init__(self, input_size, n_hidden_nodes):     # INIT\n",
    "\n",
    "        super(Net, self).__init__()                                 # Super\n",
    "        \n",
    "                                                                    # Set NN Properties\n",
    "        self.n_hidden_nodes = n_hidden_nodes                        # Number of hidden nodes in each layer\n",
    "        self.fc1 = torch.nn.Linear(input_size, n_hidden_nodes)      # Fully connected layer 1\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_nodes, n_hidden_nodes)  # Fully connected layer 2\n",
    "        self.fc3 = torch.nn.Linear(n_hidden_nodes, n_hidden_nodes)  # Fully connected layer 3\n",
    "        self.out = torch.nn.Linear(n_hidden_nodes, 1)               # Output layer\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x):                         # FORWARD\n",
    "  \n",
    "\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        x = sigmoid(self.fc1(x))        # Apply sigmoid activation to the first hidden layer\n",
    "        x = sigmoid(self.fc2(x))        # Apply sigmoid activation to the second hidden layer\n",
    "        x = sigmoid(self.fc3(x))        # Apply sigmoid activation to the third hidden layer\n",
    "\n",
    "                  \n",
    "        x = sigmoid(self.out(x))        # Get output and squash between [0, 1] via sigmoid activation\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0d6b3ca-49d6-44ad-8aaa-fa5738921fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer):\n",
    "\n",
    "    print(\"TRAINING MODEL\")\n",
    "       \n",
    "    model.train()  # Set the model in training mode\n",
    "\n",
    "    \n",
    "    \n",
    "        # Iterate over batches in the training loader\n",
    "\n",
    "    \n",
    "    \n",
    "    for images, prices in train_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        prices = prices.to(device)\n",
    "\n",
    "        \n",
    "             # Extract features & flatten into vector\n",
    "        features = resnet101(images) \n",
    "        features = features.view(features.size(0), -1) \n",
    "        \n",
    "        \n",
    "           \n",
    "        optimizer.zero_grad()     # Clear the gradients from the previous iteration\n",
    "\n",
    "        outputs = model(features)  # Forward pass: compute the model's outputs\n",
    "\n",
    "        \n",
    "            # Use mean squared error to calculate loss\n",
    "        \n",
    "        loss = torch.nn.functional.mse_loss(outputs.squeeze(), prices) \n",
    "        \n",
    "        loss.backward()           # Backpropagate the gradients\n",
    "        optimizer.step()          # Update the model's parameters using the computed gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3656be37-f2c8-4aa6-8670-cfab6a0ba002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector, model, validation_loader):\n",
    "\n",
    "    print(\"VALIDATING MODEL\")\n",
    "    \n",
    "    model.eval()              # Set the model in evaluation mode\n",
    "    \n",
    "    val_loss, correct = 0, 0  # Initialize variables for loss and correct predictions\n",
    "\n",
    "\n",
    "\n",
    "        # Iterate over batches in the validation loader\n",
    "    \n",
    "    for images, prices in validation_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        prices = prices.to(device)\n",
    "        \n",
    "\n",
    "             # Extract features & flatten into vector\n",
    "        \n",
    "        features = resnet101(images) \n",
    "        features = features.view(features.size(0), -1) \n",
    "        \n",
    "        outputs = model(features)  # Forward pass: compute the model's predictions\n",
    "        \n",
    "        val_loss += torch.nn.functional.mse_loss(outputs.squeeze(), prices).data  # Compute the mean squared loss\n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "            # Compute number of \"correct\" predictions (within 10% of target)\n",
    "        \n",
    "        deviation           = torch.abs(outputs.squeeze() - prices) / prices  # list of relative deviations from target\n",
    "        correct_predictions = (deviation <= ACCURACY_THRESHOLD).sum().item()  # number of predictions with deviation < threshold\n",
    "    \n",
    "    \n",
    "            # Update the count of correct predictions\n",
    "        \n",
    "        correct += correct_predictions\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate the accuracy as a percentage \n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)  \n",
    "\n",
    "        # Append the accuracy to a list\n",
    "\n",
    "    accuracy_vector.append(accuracy)  \n",
    "\n",
    "    val_loss /= len(validation_loader)  # Calculate the average validation loss\n",
    "    \n",
    "    loss_vector.append(val_loss)        # Append the validation loss to a list\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # Print the validation results\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c39552-a41a-4902-be6f-ad7ccaf8e427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "021f1bf1-7859-4530-88c3-1074d8bdb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    print('Using PyTorch version:', torch.__version__)\n",
    "    \n",
    "        # Load the dataset\n",
    "    \n",
    "    csv_path, artworks_path = get_art_price_dataset_path()\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "        # split dataset into training / validation sets\n",
    "    \n",
    "    train_data, validation_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "    \n",
    "        # build dataset loaders\n",
    "    \n",
    "    transform           = get_image_transform()\n",
    "    \n",
    "    train_dataset       = ArtworkDataset(train_data, artworks_path, transform=transform)\n",
    "    validation_dataset  = ArtworkDataset(validation_data,  artworks_path, transform=transform)\n",
    "    \n",
    "    train_loader        = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    validation_loader   = DataLoader(validation_dataset, batch_size=4, shuffle=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "        # create mlp\n",
    "    \n",
    "    mlp = Net(input_size = 2048, n_hidden_nodes = 512).to(device)\n",
    "    \n",
    "        # Define the optimizer for training (Stochastic Gradient Descent)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(mlp.parameters(), lr=LEARNING_RATES[2])  # Learning rate specified elsewhere\n",
    "    \n",
    "    loss_vector = []  # List to store training loss values\n",
    "    acc_vector = []   # List to store training accuracy values\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        \n",
    "        print('Epoch {}'.format(epoch))\n",
    "        \n",
    "            # Train the model on the training dataset\n",
    "        train(epoch, mlp, train_loader, optimizer)\n",
    "        \n",
    "            # Validate the model on the validation dataset and collect loss and accuracy data\n",
    "        validate(loss_vector, acc_vector, mlp, validation_loader)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb4e8f-564e-4614-98c5-c19e8d7d5c1a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99c4c19a-6c7e-4367-9c68-d05d268fd35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.6.0\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.7)\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.7)\n",
      "DATASET FOUND.   path:   /Users/jackblackburn/.cache/kagglehub/datasets/flkuhm/art-price-dataset/versions/1\n",
      "Epoch 1\n",
      "TRAINING MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/rz8ydl4561x3wb2q0wms5w540000gn/T/ipykernel_39154/4280577537.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artworks_frame['price'] = scaled_prices # set prices to scaled prices within dataframe\n",
      "/var/folders/2l/rz8ydl4561x3wb2q0wms5w540000gn/T/ipykernel_39154/4280577537.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artworks_frame['price'] = scaled_prices # set prices to scaled prices within dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0951, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 2\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.1002, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 3\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0939, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 4\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0950, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 5\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0966, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 6\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0955, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 7\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0928, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 8\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.1052, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 9\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0927, Accuracy: 1/227 (0%)\n",
      "\n",
      "Epoch 10\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0963, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 11\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.1158, Accuracy: 0/227 (0%)\n",
      "\n",
      "Epoch 12\n",
      "TRAINING MODEL\n",
      "VALIDATING MODEL\n",
      "\n",
      "Validation set: Average loss: 0.0961, Accuracy: 0/227 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7eb08-2dfb-43ca-861e-b3fc7fdb0030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
